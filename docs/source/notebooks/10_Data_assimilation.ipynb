{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10 - Data Assimilation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using PAVICS-Hydro to perform data assimilation of streamflow to prepare the model states for a forecast.\n",
    "\n",
    "Here we apply the Ensemble Kalman Filter (EnKF) data assimilation method to the initial states of a 'Raven' hydrological model, which will allow improving the estimation of the initial states to reduce the initial model bias. This also helps improve the forecast skill for shorter-term forecasts (up to a few days lead-time), and even longer in some instances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime as dt\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "import xskillscore as xss\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from ravenpy.utilities.testdata import get_file\n",
    "from ravenpy.utilities.data_assimilation import perturb_full_series, sequential_assimilation, assimilation_initialization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A note on datasets\n",
    "\n",
    "For this introduction to data assimilation, we will use pre-existing datasets that are hosted on the PAVICS-Hydro servers, as we did in the previous example notebooks. We also provide a model configuration and parameterization to keep things simple. However, you can adapt this to your own data and model setups using the tools seen in the previous notebooks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we are using a pre-defined file that is available on PAVICS-Hydro servers. \n",
    "# Replace with your own file that you can upload to your writable-workspace if desired.\n",
    "forcing = get_file(\"raven-gr4j-cemaneige/Salmon-River-Near-Prince-George_meteo_daily.nc\")\n",
    "\n",
    "# Display the datasets that we will be using\n",
    "display(forcing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Case 1: Open-loop simulation\n",
    "\n",
    "An open-loop (OL) simulation is one that is done without any data assimilation at any time step. To demonstrate the ability of the data assimilation method to improve the model states and reduce initial biases, we will compare an Open-Loop simulation to a simulation that has integrated data assimilation.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define some of the common parameters for each model run\n",
    "common_model_inputs=dict(\n",
    "    area=4250.6,\n",
    "    elevation=843.0,\n",
    "    latitude=54.4848,\n",
    "    longitude=-123.3659,\n",
    "    params=(0.1353389, -0.005067198, 576.8007, 6.986121, 1.102917, 0.9224778)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the GR4JCN model template we will be using \n",
    "from ravenpy.models import GR4JCN\n",
    "\n",
    "# Generate a GR4JCN-configured Raven model instance. \n",
    "# By replacing \"GR4JCN()\" by \"HMETS()\", we would then be running a HMETS model emulator instead. \n",
    "model = GR4JCN()\n",
    "\n",
    "# Here is where we launch the model using the configuration parameters, as well as the forcing data and start and end dates. \n",
    "model(\n",
    "    ts=forcing,\n",
    "    start_date=dt.datetime(1997, 1, 1),\n",
    "    end_date=dt.datetime(1999, 1, 1),\n",
    "    **common_model_inputs,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "openloop_hydrograph = model.hydrograph.q_sim "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Case 2: Simulation with EnKF data assimilation \n",
    "Run the model the same as before, but perform the data assimilation every 7 days during the entire period. The process is a bit more convoluted, but we will attempt to keep things as simple as possible here.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, define a set of hyperparameters to use during the assimilation steps.\n",
    "\n",
    "# Hyperparameters for the input uncertainty. \n",
    "# Note the Observed flow variable name is the CF-compliant name for discharge \"water_volume_transport_in_river_channel\"\n",
    "# Note that these values reprensent the uncertainty around the observed values. Larger values = more uncertainty.\n",
    "std={\n",
    "    \"rainfall\": 0.30,\n",
    "    \"prsn\": 0.30,\n",
    "    \"tasmin\": 2.0,\n",
    "    \"tasmax\": 2.0,\n",
    "    \"water_volume_transport_in_river_channel\": 0.10 # This is a required key! Without this variable, the assimilation will fail. This is the variable long_name attribute.\n",
    "}\n",
    "\n",
    "if \"water_volume_transport_in_river_channel\" not in std:\n",
    "    raise ValueError(\"Assimilation requires perturbing the flow variable. Please add the variable 'water_volume_transport_in_river_channel'.\")\n",
    "\n",
    "# Hyperparameters on the number of ensemble members to use for EnKF (typically 25 is a good number, here we will use 5 to keep things faster)\n",
    "n_members = 5\n",
    "\n",
    "# What are the distributions to sample from? Ex: temperature uncertainty follows a normal distribution, but precipitation follows a Gamma distribution.\n",
    "# Default is norm, so any other distribution should be specified here.\n",
    "dists = {\n",
    "    \"pr\": \"gamma\",\n",
    "    \"rainfall\": \"gamma\",\n",
    "    \"prsn\": \"gamma\",\n",
    "    \"water_volume_transport_in_river_channel\": \"rnorm\",\n",
    "}\n",
    "\n",
    "# Define which variables we want to assimilate. Here we will only adjust the water content of the 2 first layers of soil (soil0 and soil1)\n",
    "assim_var = (\"soil0\", \"soil1\")\n",
    "\n",
    "# Assimilation period (days between each assimilation step)\n",
    "assim_step_days = 7\n",
    "\n",
    "# define the start and end dates of the entire period\n",
    "start_date = dt.datetime(1997,1,1)\n",
    "end_date = dt.datetime(1999,1,1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters are ready, now we need to actually run the sequential assimilation.\n",
    "We first start by initializing a new GR4JCN model instance, and initialize the state variables so we can get an ensemble of initial states to pass to the assimilation functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's re-initialize a new model instance of GR4JCN for the assimilation part:\n",
    "model = GR4JCN()\n",
    "\n",
    "# Do the first assimilation pass to get hru_states and basin_states.\n",
    "# Can be skipped if there is already this data from a previous run.\n",
    "model, xa, hru_states, basin_states = assimilation_initialization(\n",
    "    model,\n",
    "    ts=forcing,\n",
    "    start_date=start_date,\n",
    "    end_date=start_date + dt.timedelta(days=assim_step_days - 1),\n",
    "    assim_var=assim_var,\n",
    "    n_members=n_members,\n",
    "    **common_model_inputs,\n",
    ")\n",
    "\n",
    "# This will return the model instance with n_members identical initial states at the end of the first period of assim_step_days.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we can perturb the inputs for the rest of the assimilation\n",
    "perturbed = perturb_full_series(\n",
    "    model,\n",
    "    std=std,\n",
    "    start_date=start_date,\n",
    "    end_date=end_date,\n",
    "    dists=dists,\n",
    "    n_members=n_members,\n",
    ")\n",
    "\n",
    "# Create netcdf from the perturbed inputs so we can feed the path to the Raven GR4JCN model\n",
    "p_fn = model.workdir / \"perturbed_forcing.nc\"\n",
    "perturbed = xr.Dataset(perturbed)\n",
    "perturbed.to_netcdf(p_fn, mode=\"w\")\n",
    "\n",
    "# A last step: Get observed streamflow required in the assimilation and to plot results later.\n",
    "q_obs = xr.open_dataset(forcing)[\"qobs\"].sel(time=slice(start_date, end_date))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture --no-display \n",
    "# Adding this to avoid spamming warning messages for overwriting files.\n",
    "# Finally, we now have: (1) an ensemble of initial states after the first assim_step_days and (2) perturbed hydrometeotological data for the assimilation and simulation steps. \n",
    "# We can now perform the assimilation loop and produce streamflows for the entire series:\n",
    "q_assim, hru_states, basin_states = sequential_assimilation(\n",
    "    model,\n",
    "    hru_states,\n",
    "    basin_states,\n",
    "    p_fn,\n",
    "    q_obs,\n",
    "    assim_var,\n",
    "    start_date=start_date + dt.timedelta(days=assim_step_days), # We have already \"lost\" one period during initialization.\n",
    "    end_date=end_date,\n",
    "    n_members=n_members,\n",
    "    assim_step_days=assim_step_days,\n",
    ")\n",
    "# Also note that hru_states and basin_states can be used to generate a forecast for the next time step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can now plot everything!\n",
    "plt.plot(q_assim.T, \"r\", label=None)  # plot the assimilated flows\n",
    "plt.plot(q_assim[0,:].T, \"r\", label=\"Assimilated\")  # plot the assimilated flows\n",
    "plt.plot(q_obs.T, \"b\", label=\"Observed\")  # plot the observed flows\n",
    "plt.plot(openloop_hydrograph, \"g\", label=\"Open-Loop\") # plot the open_loop (simulation with no assimilation)\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "print('RMSE - Assimilated: ' + str(xss.rmse(q_assim.mean(dim='state').T,q_obs[0:q_assim.shape[1]].T).data))\n",
    "print('RMSE - Open-Loop: ' + str(xss.rmse(openloop_hydrograph[0:q_assim.shape[1],0],q_obs[0:q_assim.shape[1]].T).data))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
