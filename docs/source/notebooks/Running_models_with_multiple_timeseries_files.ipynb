{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running a hydrological model with multiple timeseries files\n",
    "\n",
    "In this notebook, we show how to provide the hydrological model with multiple timeseries files. For example, one file could contain meteorological data and the other contain streamflow data, or all variables could be separate (i.e. precip, temperature, streamflow, etc.). The following instructions should make it easier to understand how to do this. for this example, we actually start from a netcdf file containing all information, and from there divide it into multiple time series netcdf files. We then use the split files to drive the model. In most user cases, different files will be provided directly by the user so no need to pre-split your files!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cookie-cutter template necessary to provide the tools, packages and paths for the project. All notebooks\n",
    "# need this template (or a slightly adjusted one depending on the required packages)\n",
    "from birdy import WPSClient\n",
    "\n",
    "from example_data import TESTDATA\n",
    "import datetime as dt\n",
    "from pathlib import Path\n",
    "from urllib.request import urlretrieve\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import os\n",
    "import json\n",
    "import netCDF4 as nc\n",
    "from zipfile import ZipFile\n",
    "import glob\n",
    "import tempfile\n",
    "\n",
    "# Set environment variable RAVEN_WPS_URL to \"http://localhost:9099\" to run on the default local server\n",
    "url = os.environ.get(\"RAVEN_WPS_URL\", \"https://pavics.ouranos.ca/twitcher/ows/proxy/raven/wps\")\n",
    "wps = WPSClient(url)\n",
    "\n",
    "# DATA MAIN SOURCE - DAP link to CANOPEX dataset\n",
    "CANOPEX_DAP = 'https://pavics.ouranos.ca/twitcher/ows/proxy/thredds/dodsC/birdhouse/ets/Watersheds_5797_cfcompliant.nc'\n",
    "CANOPEX_URL = 'https://pavics.ouranos.ca/twitcher/ows/proxy/thredds/fileServer/birdhouse/ets/Watersheds_5797_cfcompliant.nc'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup some parameters to run the models. See the \"canopex.ipynb\" notebook for more detailed information\n",
    "# on these parameters. The data we use comes from the extended CANOPEX database.\n",
    "start = dt.datetime(1998, 1, 1)\n",
    "stop = dt.datetime(2010, 12, 31)\n",
    "watershedID = 5600"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# With this info, we can gather some properties from the CANOPEX database:\n",
    "tmp=pd.read_csv(TESTDATA['canopex_attributes'])\n",
    "basin_area=tmp['area'][watershedID]\n",
    "basin_latitude = tmp['latitude'][watershedID]\n",
    "basin_longitude = tmp['longitude'][watershedID]\n",
    "basin_elevation = tmp['elevation'][watershedID]\n",
    "basin_name=ds.watershed[watershedID].data\n",
    "\n",
    "print(\"Basin name: \", basin_name)\n",
    "print(\"Latitude: \", basin_latitude, \" Â°N\")\n",
    "print(\"Area: \", basin_area, \" km^2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ideally we would be able to pass the DAP link directly to Raven, but there are still some issues \n",
    "# to fix to be able to do that. For now, we'll download the series at the point of interest. \n",
    "path = Path(tempfile.mkdtemp()) /  \"ts.nc\"\n",
    "ts = ds.isel(watershed=watershedID).sel(time=slice(start, stop))\n",
    "ts.to_netcdf(path)\n",
    "\n",
    "# Add precision on time format for Raven\n",
    "D = nc.Dataset(path, mode=\"a\")\n",
    "D.variables[\"time\"].units += \" 00:00:00\"\n",
    "D.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SECTION TO SEPARATE DISCHARGE AND MET DATA TO RECOMBINE LATER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the 2 new files, i.e. the meteorological data and the streamflow data\n",
    "filepathMet = os.getcwd()+\"/CANOPEX_Met.nc\"\n",
    "filepathQobs=os.getcwd()+\"/CANOPEX_Qobs.nc\"\n",
    "\n",
    "# Do the extraction for the selected catchment\n",
    "basindata=xr.open_dataset(CANOPEX_DAP)\n",
    "newBasin=basindata.isel(watershed=watershedID)\n",
    "\n",
    "# Generate the streamflow time-series netcdf\n",
    "Qobsfile = newBasin['discharge']\n",
    "Qobsfile.to_netcdf(filepathQobs)\n",
    "D = nc.Dataset(filepathQobs, mode=\"a\")\n",
    "D.variables[\"time\"].units += \" 00:00:00\"\n",
    "D.close()\n",
    "\n",
    "# Generate the meteorological time-series netcdf\n",
    "newBasin=newBasin[['drainage_area','pr','tasmax','tasmin']]\n",
    "newBasin.to_netcdf(filepathMet)\n",
    "D = nc.Dataset(filepathMet, mode=\"a\")\n",
    "D.variables[\"time\"].units += \" 00:00:00\"\n",
    "D.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Here is where we run the model with multiple input time series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The model parameters. We are forcing values here just so the model runs, the models are probably very bad choices!\n",
    "\n",
    "params = '9.5019, 0.2774, 6.3942, 0.6884, 1.2875, 5.4134, 2.3641, 0.0973, 0.0464, 0.1998, 0.0222, -1.0919, ' \\\n",
    "         '2.6851, 0.3740, 1.0000, 0.4739, 0.0114, 0.0243, 0.0069, 310.7211, 916.1947'\n",
    "\n",
    "# Model configuration parameters. Please see \"canopex.ipynb\" for more details. \n",
    "# This remains unchanged with multiple timeseries!\n",
    "config = dict(\n",
    "    start_date=start,\n",
    "    end_date=stop,\n",
    "    area=basin_area,\n",
    "    elevation=basin_elevation,\n",
    "    latitude=basin_latitude,\n",
    "    longitude=basin_longitude,\n",
    "    run_name='test_hmets_NRCAN',\n",
    "    rain_snow_fraction='RAINSNOW_DINGMAN', \n",
    "    nc_spec=json.dumps({'tasmax': {'linear_transform': (1.0, -273.15)},'tasmin': {'linear_transform': (1.0, -273.15)},'pr': {'linear_transform': (86400.0, 0.0)}},),\n",
    ")\n",
    "\n",
    "\n",
    "# Here is where we must tell the model that there are multiple input files. The idea is to combine them into a list of strings,\n",
    "# with each string representing a path to a netcdf file. So we could do something like this:\n",
    "ts_combined=[str(filepathMet),str(filepathQobs)]\n",
    "resp = wps.raven_hmets(ts=ts_combined, params=params, **config)\n",
    "\n",
    "# And get the response\n",
    "# With `asobj` set to False, only the reference to the output is returned in the response. \n",
    "# Setting `asobj` to True will retrieve the actual files and copy the locally. \n",
    "[hydrograph, storage, solution, diagnostics, rv] = resp.get(asobj=True)\n",
    "print(diagnostics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### You can even invert the order of the netcdf files. Raven will detect which files contain which variables, so the order is not important!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test with reversed timeseries files:\n",
    "ts_combined=[str(filepathQobs),str(filepathMet)]\n",
    "resp = wps.raven_hmets(ts=ts_combined, params=params, **config)\n",
    "\n",
    "# And get the response\n",
    "# With `asobj` set to False, only the reference to the output is returned in the response. \n",
    "# Setting `asobj` to True will retrieve the actual files and copy the locally. \n",
    "[hydrograph, storage, solution, diagnostics, rv] = resp.get(asobj=True)\n",
    "print(diagnostics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### As you can see, the NSE values and RMSE values are identical. You can pass as many NetCDF files as you have variables in any order and it will still work."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
