{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 03 - Extract geographical watershed properties"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract geographical watershed properties automatically using PAVICS-Hydro's geospatial toolbox\n",
    "\n",
    "Hydrological models typically need geographical information about watersheds being simulated: latitude and longitude, area, mean altitude, land-use, etc. Raven is no exception. This notebook shows how to obtain this information using remote services that are made available for users in PAVICS-Hydro. These services connect to a digital elevation model (DEM) and a land-use data set to extract relevant information.\n",
    "\n",
    "The DEM used in the following is the [EarthEnv-DEM90](https://www.earthenv.org/DEM), while the land-use dataset is the [North American Land Change Monitoring System](http://www.cec.org/tools-and-resources/north-american-environmental-atlas/north-american-land-change-monitoring-system). Other data sources could be used, given their availability through the Web Coverage Service (WCS) protocol.\n",
    "\n",
    "Since these computations happen on a specific Geoserver hosted in PAVICS, we need to establish a connection to that service. While the steps are a bit more complex, the good news is that you only need to change a few items in this notebook to taylor results to your needs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We need to import a few packages required to do the work\n",
    "import json\n",
    "import os\n",
    "from zipfile import ZipFile\n",
    "from birdy import WPSClient\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import rasterio\n",
    "import rioxarray as rio\n",
    "import xarray as xr\n",
    "\n",
    "# This is the URL of the Geoserver that will perform the computations for us.\n",
    "url = os.environ.get(\"WPS_URL\", \"https://pavics.ouranos.ca/twitcher/ows/proxy/raven/wps\")\n",
    "\n",
    "# Connect to the PAVICS-Hydro Raven WPS server\n",
    "wps = WPSClient(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Watershed contour / shapefile\n",
    "\n",
    "We first extract the watershed contour for the point of interest. If you already have the contours in shapefile or GeoJSON format, then you can skip this section and go to the \"Display contour\" section. \n",
    "\n",
    "The process looks into the HydroSHEDS database to finds the watershed enclosing the given location. The `location` parameter identifies the outlet of the watershed, and `aggregate_upstream` determines whether or not we want the service to return the union of all upstream basins. Here we set it to `False` to reduce the size of the basin and speed-up computations.\n",
    "\n",
    "The output of the `hydrosheds-select` process is a GeoJSON file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Run this section to extract a watershed from the HydroSHEDS database:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "select_resp = wps.hydrobasins_select(\n",
    "    location=\"-71.291660, 50.492758\", \n",
    "    aggregate_upstream=False\n",
    ")\n",
    "\n",
    "# Get GeoJSON polygon of the delineated watershed.\n",
    "# We can either get links to the files stored on the server, or get the data directly.\n",
    "\n",
    "# Get the links\n",
    "feature_url, upstream_basins_url = select_resp.get(asobj=False)\n",
    "print(\"This is the geoJSON file that can be used as the basin contour in other toolboxes:\")\n",
    "print(feature_url)\n",
    "print(\"\")\n",
    "\n",
    "# Get the data directly\n",
    "feature, upstream_basins = select_resp.get(asobj=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now plot the outline of the watershed by loading it into `GeoPandas`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you have a file, you can upload it here (shapefiles must be zipped with the .prj, .shx, .shp, and other such files into a single zip file) and pass the filename.\n",
    "# Ex: df = gpd.read_file(\"my_basin_shapefile.zip\")\n",
    "\n",
    "# Here we are using the result of the above computation.\n",
    "df = gpd.read_file(feature_url)\n",
    "display(df)\n",
    "df.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generic watershed properties\n",
    "\n",
    "Now that we have delineated a watershed, lets find the zonal statistics and other properties using the `shape_properties` process. This process requires a `shape` argument defining the watershed contour, the exterior polygon. The polygon can be given either as a link to a geometry file  (e.g. a geojson file such as `feature_url`), or as data embeded in a string. For example, if variable `feature` is a `GeoPandas` geometry, `json.dumps(feature)` can be used to convert it to a string and pass it as the `shape` argument.\n",
    "\n",
    "Typically, we expect users will simply upload a shapefile and use this code to perform the extraction on the region of interest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shape_resp = wps.shape_properties(shape=feature_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the process has completed, we extract the data from the response, as follows. Note that you do not need to change anything here. The code will work and return the desired results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[properties,] = shape_resp.get(asobj=True)\n",
    "prop = properties[0]\n",
    "display(prop)\n",
    "\n",
    "area = prop[\"area\"] / 1000000.0\n",
    "longitude = prop[\"centroid\"][0]\n",
    "latitude = prop[\"centroid\"][1]\n",
    "gravelius = prop[\"gravelius\"]\n",
    "perimeter = prop[\"perimeter\"]\n",
    "\n",
    "shape_info = {\n",
    "    \"area\": area,\n",
    "    \"longitude\": longitude,\n",
    "    \"latitude\": latitude,\n",
    "    \"gravelius\": gravelius,\n",
    "    \"perimeter\": perimeter,\n",
    "}\n",
    "display(shape_info)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that these properties are a mix of the properties of the original file where the shape is stored, and properties computed by the process (area, centroid, perimeter and gravelius). Note also that the computed area is in m², while the \"SUB_AREA\" property is in km², and that there are slight differences between the two values due to the precision of HydroSHEDS and the delineation algorithm.\n",
    "\n",
    "## Land-use information\n",
    "\n",
    "Now we extract the land-use properties of the watershed using the `nalcms_zonal_stats` process. As mentionned, it uses the [North American Land Change Monitoring System](http://www.cec.org/tools-and-resources/north-american-environmental-atlas/north-american-land-change-monitoring-system) dataset, and retrieve properties over the given region.\n",
    "\n",
    "With the `nalcms_zonal_stats_raster` process, we also return the grid with variable accessors (`gdal`, `rasterio`, or `rioxarray`) depending on what libraries are available in our runtime environment (The following examples show `rioxarray`-like access)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_resp = wps.nalcms_zonal_stats_raster(\n",
    "    shape=feature_url, \n",
    "    select_all_touching=True, \n",
    "    band=1, \n",
    "    simple_categories=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we will get the raster data and show it as a grid. These values can be exported to the user path to download them and use them offline.\n",
    "\n",
    "Note that GeoJSON, and rasterio/rioxarray need to be installed for this to work. In the next birdy release, the tiff grid will be automatically converted to a DataArray.\n",
    "\n",
    "Here we need to manually convert it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features, statistics, grid = stats_resp.get(asobj=True)\n",
    "grid[0].plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From there, it's easy to calculate the ratio and percentages of each land-use component. This code should also be left as-is unless you really know what you are doing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lu = statistics[0]\n",
    "total = sum(lu.values())\n",
    "\n",
    "land_use = {k: (v / total) for (k, v) in lu.items()}\n",
    "display(\"Land use ratios\", land_use)\n",
    "\n",
    "precision = 2\n",
    "land_use_pct = {\n",
    "    k: \"{} %\".format(int((v / total) * 100 * 10 ** precision) / 10 ** precision)\n",
    "    for (k, v) in lu.items()\n",
    "}\n",
    "display(\"Land use percentages\", land_use_pct)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display the land-use statistics\n",
    "Here we can display the land-use statistics according to the land cover map, as a function of land cover raster pixels over the catchment. Again, this does not need to be modified at all. It can also be simply deleted if the visualization tools are not required for your use-case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique, counts = np.unique(\n",
    "    grid[0], \n",
    "    return_counts=True\n",
    ")\n",
    "display(unique, counts)\n",
    "\n",
    "# Pixels values at '127' are NaN and can be ignored.\n",
    "plt.bar(unique[:-1], counts[:-1])\n",
    "plt.xticks(np.arange(min(unique[:-1]), max(unique[:-1])+1, 1.0))\n",
    "plt.xlabel('Land-use categories')\n",
    "plt.ylabel('Number of pixels')\n",
    "plt.show()\n",
    "\n",
    "grid[0].where(grid[0] != 127).sel(band=1).plot.imshow(cmap=\"tab20\")\n",
    "grid[0].name = \"Land-use categories\"\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also receive the geotiff object as an `xarray.Dataset` with the `.open_rasterio()` method. This makes it very easy to spatially reproject it with the `cartopy` library. Here we provide a sample projection, but this would need to be adapted to your needs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cartopy.crs as ccrs\n",
    "\n",
    "# Set a CRS transformation:\n",
    "crs = ccrs.LambertConformal(\n",
    "    central_latitude=49, \n",
    "    central_longitude=-95, \n",
    "    standard_parallels=(49, 77)\n",
    ")\n",
    "\n",
    "ax = plt.subplot(projection=crs)\n",
    "grid[0].name = \"Land-use categories\"\n",
    "grid[0].where(grid[0] != 127).sel(band=1).plot.imshow(\n",
    "    ax=ax, \n",
    "    transform=crs, \n",
    "    cmap=\"tab20\"\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Terrain information from the DEM\n",
    "\n",
    "Here we collect terrain data, such as elevation, slope and aspect, from the DEM. We will do this using the `terrain_analysis` WPS service, which by default uses DEM data from [EarthEnv-DEM90](https://www.earthenv.org/DEM).\n",
    "\n",
    "Note here that while the feature outline is defined above in terms of geographic coordinates (latitude, longitude), the DEM is projected onto a 2D cartesian coordinate system (here NAD83, the Canada Atlas Lambert projection). This is necessary to perform slope calculations. For more information on this, see: https://en.wikipedia.org/wiki/Map_projection\n",
    "\n",
    "The DEM data returned in the process response here shows `rioxarray`-like access but using the URLs we can open the files however we like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "terrain_resp = wps.terrain_analysis(\n",
    "    shape=feature_url, \n",
    "    select_all_touching=True, \n",
    "    projected_crs=3978\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "properties, dem = terrain_resp.get(asobj=True)\n",
    "\n",
    "elevation = properties[0][\"elevation\"]\n",
    "slope = properties[0][\"slope\"]\n",
    "aspect = properties[0][\"aspect\"]\n",
    "\n",
    "terrain = {\n",
    "    \"elevation\": elevation, \n",
    "    \"slope\": slope, \n",
    "    \"aspect\": aspect\n",
    "}\n",
    "display(terrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "crs = ccrs.LambertConformal(\n",
    "    central_latitude=49, \n",
    "    central_longitude=-95, \n",
    "    standard_parallels=(49, 77)\n",
    ")\n",
    "\n",
    "dem.name = \"Elevation\"\n",
    "dem.attrs[\"units\"] = \"m\"\n",
    "ax = plt.subplot(projection=crs)\n",
    "dem.where(dem != -32768).sel(band=1).plot.imshow(\n",
    "    ax=ax, \n",
    "    transform=crs, \n",
    "    cmap=\"gnuplot\"\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can also access the files directly via their URLs:\n",
    "properties, dem = terrain_resp.get(asobj=False)\n",
    "display(properties, dem)\n",
    "\n",
    "# Let's read the data from band=1 as numpy array\n",
    "display(rasterio.open(dem).read(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "A synthesis of all watershed properties can be created by merging the various dictionaries created. This allows users to easily access any of these values, and to provide them to Raven as needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "all_properties = {**shape_info, **land_use, **terrain}\n",
    "display(all_properties)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
