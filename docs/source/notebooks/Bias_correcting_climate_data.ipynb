{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bias-correcting climate data and generating future streamflows with RAVEN\n",
    "\n",
    "This notebook shows how to bias-correct climate data to drive a hydrological model and get future streamflow values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This entire section is cookie-cutter template to allow calling the servers and instantiating the connection\n",
    "# to the WPS server. Do not modify this block.\n",
    "\n",
    "from pathlib import Path\n",
    "from urllib.request import urlretrieve\n",
    "from zipfile import ZipFile\n",
    "import glob\n",
    "import json\n",
    "import os\n",
    "import datetime as dt\n",
    "import tempfile\n",
    "\n",
    "from birdy import WPSClient\n",
    "from matplotlib import pyplot as plt\n",
    "import xclim\n",
    "from xclim import sdba\n",
    "import fiona\n",
    "import netCDF4 as nc\n",
    "import numpy as np\n",
    "import rioxarray\n",
    "import shapely\n",
    "import xarray as xr\n",
    "\n",
    "from ravenpy.utilities.testdata import get_file\n",
    "\n",
    "# Set environment variable WPS_URL to \"http://localhost:9099\" to run on the default local server\n",
    "url = os.environ.get(\"WPS_URL\", \"https://pavics.ouranos.ca/twitcher/ows/proxy/raven/wps\")\n",
    "wps = WPSClient(url)\n",
    "\n",
    "# Temporary directory to store meteorological data\n",
    "tmp = Path(tempfile.mkdtemp())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will first need to process the catchment boundaries from the zipped shapefile.\n",
    "# Users can provide shapefiles of their own or use the region selection tools to define\n",
    "# a watershed. This is necessary to obtain the latitude and longitude of the catchment that\n",
    "# we need to extract from the climate model data and reference data.\n",
    "\n",
    "# The shapefile of the catchment. All files (.shp, .shx, etc.) must be zipped into one file. \"vec\" is a string\n",
    "# or Posix Path pointing to the zipped watershed contour file location.\n",
    "vec = get_file('watershed_vector/LSJ_LL.zip')\n",
    "\n",
    "# Choose a hydrological model to use. We have 'HMETS', 'GR4JCN','MOHYSE' and 'HBVEC'.\n",
    "hydromodel = 'HMETS'\n",
    "\n",
    "# Extract the contours and lat/long bounding boxes\n",
    "ZipFile(vec,'r').extractall(tmp)\n",
    "shp = list(tmp.glob(\"*.shp\"))[0]\n",
    "vector = fiona.open(shp, \"r\")\n",
    "\n",
    "lon_min=vector.bounds[0]\n",
    "lon_max=vector.bounds[2]\n",
    "lat_min=vector.bounds[1]\n",
    "lat_max=vector.bounds[3]\n",
    "\n",
    "# Get access to the geometry using the fiona API\n",
    "shdf = [vector.next()[\"geometry\"]]\n",
    "\n",
    "# Define some of the catchment properties. Could also be replaced by a call to the properties WPS!\n",
    "basin_area = 4523.5\n",
    "basin_longitude = -72.55\n",
    "basin_latitude = 48.39"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xclim import subset\n",
    "\n",
    "# For now, we use the centroid to extract a large-ish zone around the catchment center \n",
    "# (2 degrees x 2 degrees). We can replace this later with calls that are specific to \n",
    "# the points within a watershed.\n",
    "\n",
    "lat=basin_latitude\n",
    "lon=basin_longitude\n",
    "\n",
    "# Access to the datasets for future and reference period (climate model) and historical (observed or proxy)\n",
    "fut_data='https://pavics.ouranos.ca/twitcher/ows/proxy/thredds/dodsC/datasets/simulations/bias_adjusted/cmip5/nasa/nex-gddp-1.0/day_inmcm4_historical+rcp85_nex-gddp.ncml'\n",
    "ref_data='https://pavics.ouranos.ca/twitcher/ows/proxy/thredds/dodsC/datasets/simulations/bias_adjusted/cmip5/nasa/nex-gddp-1.0/day_inmcm4_historical+rcp45_nex-gddp.ncml'\n",
    "hist_data=\"https://pavics.ouranos.ca/twitcher/ows/proxy/thredds/dodsC/datasets/gridded_obs/nrcan_v2.ncml\"\n",
    "\n",
    "# Open these datasets\n",
    "ds_fut=xr.open_dataset(fut_data)\n",
    "ds_ref=xr.open_dataset(ref_data)\n",
    "ds_his=xr.open_dataset(hist_data)\n",
    "\n",
    "# Subset the data to the desired location (2x2 degree box)\n",
    "ds_fut_sub =subset.subset_bbox(ds_fut, lon_bnds=[lon-1, lon+1], lat_bnds=[lat-1, lat+1], start_date='2070', end_date='2079').mean(dim={'lat','lon'},keep_attrs=True)\n",
    "ds_ref_sub =subset.subset_bbox(ds_ref, lon_bnds=[lon-1, lon+1], lat_bnds=[lat-1, lat+1], start_date='1971', end_date='1980').mean(dim={'lat','lon'},keep_attrs=True)\n",
    "ds_his_sub =subset.subset_bbox(ds_his, lon_bnds=[lon-1, lon+1], lat_bnds=[lat-1, lat+1], start_date='1971', end_date='1980').mean(dim={'lat','lon'},keep_attrs=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the bias correction\n",
    "import nc_time_axis\n",
    "import cftime\n",
    "\n",
    "# We will apply the statistics per month\n",
    "group_month_nowindow = sdba.utils.Grouper('time.month')\n",
    "\n",
    "# Here we specify that we want to use the Detrended Quantile Mapping method. See XCLIM documents for more methods and info.\n",
    "Adj = sdba.DetrendedQuantileMapping(nquantiles=50, kind='+', group=group_month_nowindow)\n",
    "\n",
    "# Train the model to find the correction factors\n",
    "Adj.train(ds_ref_sub['pr'],ds_his_sub['pr'])\n",
    "\n",
    "# Apply the factors to the future data to bias-correct\n",
    "Scen_pr = Adj.adjust(ds_fut_sub['pr'], interp=\"linear\")\n",
    "\n",
    "## Repeat for temperature max\n",
    "Adj.train(ds_ref_sub['tasmax'],ds_his_sub['tasmax'])\n",
    "\n",
    "## Apply the factors to the future data to bias-correct\n",
    "Scen_tasmax = Adj.adjust(ds_fut_sub['tasmax'], interp=\"linear\")\n",
    "\n",
    "# Repeat for tasmin\n",
    "Adj.train(ds_ref_sub['tasmin'],ds_his_sub['tasmin'])\n",
    "Scen_tasmin = Adj.adjust(ds_fut_sub['tasmin'], interp=\"linear\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import timedelta\n",
    "# Ensure that the precipitation is non-negative, which can happen with some climate models\n",
    "Scen_pr[Scen_pr<0] = 0\n",
    "\n",
    "# Convert the data arrays to datasets\n",
    "ds_Scen_pr = Scen_pr.to_dataset(name='pr')\n",
    "ds_Scen_tasmax = Scen_tasmax.to_dataset(name='tasmax')\n",
    "ds_Scen_tasmin = Scen_tasmin.to_dataset(name='tasmin')\n",
    "\n",
    "## Write these variables to a unique netcdf\n",
    "bias_corrected_met = xr.merge([ds_Scen_pr,ds_Scen_tasmax,ds_Scen_tasmin], compat='override')\n",
    "tsfile=tmp / 'ClimateModelFuture_ts4.nc'\n",
    "bias_corrected_met.to_netcdf(tsfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time and conversion factors for the hydrological model run. We want to run the future\n",
    "# period, so start and stop dates reflect this to match the data we extracted earlier.\n",
    "start = dt.datetime(2070, 1, 1)\n",
    "stop = dt.datetime(2079, 12, 31)\n",
    "\n",
    "# Transforms that are 2-parameters of a linear equation ax + b, so temperature uses a=1.0 and b = -273.15 to bring K to degC.\n",
    "nc_transforms = json.dumps({'tasmax': {'linear_transform': (1.0, -273.15)},'tasmin': {'linear_transform': (1.0, -273.15)},'pr': {'linear_transform': (86400.0, 0.0)}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model configuration parameters\n",
    "config = dict(\n",
    "    start_date=start, \n",
    "    end_date=stop,\n",
    "    area=basin_area,\n",
    "    elevation=82.2,\n",
    "    latitude=basin_latitude,\n",
    "    longitude=basin_longitude,\n",
    "    run_name='test_bias_correction_' + hydromodel,\n",
    "    nc_spec= nc_transforms\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here is where the magic happens, and the RAVEN modeling framework parses the information that we give it\n",
    "# to run the hydrological model that we chose with the dataset that we chose.\n",
    "\n",
    "# Here we provide a set of hydrological model parameters by default, but these can be adjusted, modified or calibrated later.\n",
    "if hydromodel=='HMETS':\n",
    "    params = '9.5019, 0.2774, 6.3942, 0.6884, 1.2875, 5.4134, 2.3641, 0.0973, 0.0464, 0.1998, 0.0222, -1.0919,2.6851, 0.3740, 1.0000, 0.4739, 0.0114, 0.0243, 0.0069, 310.7211, 916.1947'\n",
    "    resp = wps.raven_hmets(ts=str(tsfile), params=params, rain_snow_fraction='RAINSNOW_DINGMAN', **config,)\n",
    "    \n",
    "elif hydromodel=='GR4JCN':\n",
    "    params = '0.529, -3.396, 407.29, 1.072, 16.9, 0.947'\n",
    "    resp = wps.raven_gr4j_cemaneige(ts=str(tsfile), params = params, **config)\n",
    "    \n",
    "elif hydromodel=='MOHYSE':\n",
    "    params = '1.00, 0.0468, 4.2952, 2.6580, 0.4038, 0.0621, 0.0273, 0.0453'\n",
    "    hrus = '0.9039, 5.6179775' # MOHYSE has a particular setup that requires parameters for HRUs.\n",
    "    resp = wps.raven_mohyse(ts=str(tsfile), params = params, hrus=hrus, rain_snow_fraction='RAINSNOW_DINGMAN', **config)  \n",
    "    \n",
    "elif hydromodel=='HBVEC':\n",
    "    params = '0.05984519, 4.072232, 2.001574, 0.03473693, 0.09985144, 0.5060520, 3.438486, 38.32455, 0.4606565, 0.06303738, 2.277781, 4.873686, 0.5718813, 0.04505643, 0.877607, 18.94145, 2.036937, 0.4452843, 0.6771759, 1.141608, 1.024278'\n",
    "    resp = wps.raven_hbv_ec(ts=str(tsfile), evaporation=\"PET_OUDIN\", ow_evaporation=\"PET_OUDIN\", params=params, **config)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The model has run! We can get the response.\n",
    "# With `asobj` set to False, only the reference to the output is returned in the response. \n",
    "# Setting `asobj` to True will retrieve the actual files and copy them locally. \n",
    "[hydrograph, storage, solution, diagnostics, rv] = resp.get(asobj=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we requested output objects, we can simply access the output objects. The dianostics is just a CSV file: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `hydrograph` and `storage` outputs are netCDF files storing the time series. These files are opened by default using `xarray`, which provides convenient and powerful time series analysis and plotting tools. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas.plotting import register_matplotlib_converters\n",
    "register_matplotlib_converters()\n",
    "\n",
    "hydrograph.q_sim.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hydrograph['time']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## If we want, we can also download the simulation data and analyze it on our own computer, software and tools:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-extract the WPS Server response, but this time set the \"asobj\" to False to return the file path.\n",
    "[hydrograph, storage, solution, diagnostics, rv] = resp.get(asobj=False)\n",
    "print(hydrograph)\n",
    "print(storage)\n",
    "print(solution)\n",
    "print(diagnostics)\n",
    "print(rv)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
