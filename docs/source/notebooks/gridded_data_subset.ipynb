{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running a hydrological model over a watershed defined by a shapefile\n",
    "\n",
    "This notebook shows how to run Raven over a user-defined watershed. The watershed contour is provided by a shapefile, which we use to subset meteorological data and to extract watershed physiographic properties. The meteorological data is spatially averaged, then fed to the Raven hydrological model to simulate streamflow. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This entire section is cookie-cutter template to allow calling the servers and instantiating the connection\n",
    "# to the WPS server. Do not modify this block.\n",
    "\n",
    "from pathlib import Path\n",
    "from urllib.request import urlretrieve\n",
    "from zipfile import ZipFile\n",
    "import glob\n",
    "import json\n",
    "import os\n",
    "import datetime as dt\n",
    "import tempfile\n",
    "\n",
    "from birdy import WPSClient\n",
    "from matplotlib import pyplot as plt\n",
    "from xclim import subset\n",
    "import fiona\n",
    "import netCDF4 as nc\n",
    "import numpy as np\n",
    "import rioxarray\n",
    "import shapely\n",
    "import xarray as xr\n",
    "\n",
    "from example_data import TESTDATA\n",
    "\n",
    "# Set environment variable WPS_URL to \"http://localhost:9099\" to run on the default local server\n",
    "url = os.environ.get(\"WPS_URL\", \"https://pavics.ouranos.ca/twitcher/ows/proxy/raven/wps\")\n",
    "wps = WPSClient(url)\n",
    "\n",
    "# Temporary directory to store meteorological data\n",
    "tmp = Path(tempfile.mkdtemp())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SETUP THE RUN PARAMETERS. The data will be extracted to cover the simulation period\n",
    "\n",
    "start = dt.datetime(2001, 1, 1)\n",
    "stop = dt.datetime(2002, 12, 31)\n",
    "UTCoffset_hours = -6 # for UTC delta\n",
    "\n",
    "# The shapefile of the catchment. All files (.shp, .shx, etc.) must be zipped into one file. \"vec\" is a string\n",
    "# or Posix Path pointing to the zipped watershed contour file location.\n",
    "vec = TESTDATA['watershed_vector']\n",
    "print(\"The file location is: \" + str(vec))\n",
    "\n",
    "# Choose a dataset to use. We have 'NRCAN' and 'ERA5' for now. \n",
    "# NRCAN is only available in Canada, while ERA5 is global.\n",
    "dataset = 'ERA5' \n",
    "\n",
    "# Choose a hydrological model to use. We have 'HMETS', 'GR4JCN','MOHYSE' and 'HBVEC'.\n",
    "hydromodel = 'HMETS'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will first need to process the catchment boundaries from the zipped shapefile. \n",
    "ZipFile(vec,'r').extractall(tmp)\n",
    "shp = list(tmp.glob(\"*.shp\"))[0]\n",
    "vector = fiona.open(shp, \"r\")\n",
    "\n",
    "lon_min=vector.bounds[0]\n",
    "lon_max=vector.bounds[2]\n",
    "lat_min=vector.bounds[1]\n",
    "lat_max=vector.bounds[3]\n",
    "\n",
    "# Get access to the geometry using the fiona API\n",
    "shdf = [vector.next()[\"geometry\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From the shapefile, call the PAVICS-Hydro service to extract properties such as centroid lat/long, elevation and area.\n",
    "resp = wps.shape_properties(shape=str(vec))\n",
    "[properties, ]=resp.get(asobj=True)\n",
    "prop = properties[0]\n",
    "basin_area = prop['area']/1000000.0\n",
    "basin_longitude = prop['centroid'][0]\n",
    "basin_latitude = prop['centroid'][1]\n",
    "\n",
    "# This uses the HydroSheds DEM\n",
    "resp = wps.terrain_analysis(shape=str(vec), select_all_touching=True, projected_crs=3978)\n",
    "properties, dem = resp.get(asobj=True)\n",
    "basin_elevation=properties[0]['elevation']\n",
    "\n",
    "print(\"Area: \", basin_area)\n",
    "print(\"Elevation: \", basin_elevation)\n",
    "print(\"Longitude: \", basin_longitude)\n",
    "print(\"Latitude: \", basin_latitude)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if dataset=='NRCAN':\n",
    "    # Define the path to the netcdf file and write to disk (the basin averaged data)\n",
    "    tsfile= tmp / 'NRCAN_ts.nc'\n",
    "    \n",
    "    if not tsfile.exists():\n",
    "        # Path to unified NetCDF ML dataset file on the THREDDS server (OPeNDAP link)\n",
    "        NRCAN_url='https://pavics.ouranos.ca/twitcher/ows/proxy/thredds/dodsC/birdhouse/1-Datasets/gridded_obs/nrcan_v2.ncml'\n",
    "\n",
    "        #Open the dataset file and slice the desired lat/lon (+1Â°Buffer) and limit to the time simulation duration\n",
    "        ds=xr.open_dataset(NRCAN_url).sel(lat=slice(lat_max+1,lat_min-1), lon=slice(lon_min-1,lon_max+1), time=slice(start, stop))\n",
    "        \n",
    "        # Rioxarray requires CRS definitions for variables\n",
    "        tas = ds.tas.rio.write_crs(4326)\n",
    "        pr = ds.pr.rio.write_crs(4326)\n",
    "        ds = xr.merge([tas, pr])\n",
    "        \n",
    "        # Now apply the mask of the basin contour and average the values to get a single time series\n",
    "        sub = ds.rio.clip(shdf, crs=4326)\n",
    "        sub = sub.mean(dim={'lat','lon'}, keep_attrs=True)\n",
    "        \n",
    "        # Define the path to the netcdf file and write to disk (the basin averaged data)\n",
    "        sub.to_netcdf(tsfile)\n",
    "    \n",
    "    # Prepare the linear transform parameters for the hydrological model run.\n",
    "    nc_transforms = json.dumps({'tasmax': {'linear_transform': (1.0, -273.15)},'tasmin': {'linear_transform': (1.0, -273.15)},'pr': {'linear_transform': (86400.0, 0.0)}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if dataset=='ERA5':\n",
    "    tsfile=tmp / 'ERA5_ts.nc'\n",
    "    day = dt.timedelta(days=1)\n",
    "    if not tsfile.exists():    \n",
    "        ERA5_url='https://pavics.ouranos.ca/twitcher/ows/proxy/thredds/dodsC/birdhouse/1-Datasets/reanalyses/era5.ncml'\n",
    "        ds=xr.open_dataset(ERA5_url).sel(latitude=slice(lat_max+1,lat_min-1), longitude=slice(lon_min+360-1,lon_max+360+1),time=slice(start - day, stop + day))\n",
    "\n",
    "        # Special treatment for ERA5 in North America: ECMWF stores ERA5 longitude in 0:360 format rather than -180:180. We need to reassign the longitudes here\n",
    "        ds = ds.assign_coords({'longitude':ds['longitude'].values[:]-360})\n",
    "        \n",
    "        # Rioxarray requires CRS definitions for variables\n",
    "        tas = ds.tas.rio.write_crs(4326)\n",
    "        pr = ds.pr.rio.write_crs(4326)\n",
    "        ds = xr.merge([tas, pr])\n",
    "        \n",
    "        sub = ds.rio.clip(shdf, crs=ds.tas.rio.crs)\n",
    "        sub = sub.mean(dim={'latitude','longitude'}, keep_attrs=True)\n",
    "\n",
    "        # Define the path to the netcdf file and write to disk (the basin averaged data)\n",
    "        sub.to_netcdf(tsfile)\n",
    "    \n",
    "    #Perform the linear transform and time shift\n",
    "    nc_transforms=json.dumps({'tas': {'linear_transform': (1.0, -273.15), 'time_shift': UTCoffset_hours/24}, 'pr': {'linear_transform': (24000.0, 0.0), 'time_shift': UTCoffset_hours/24}})     \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map of precip snapshot\n",
    "ds.pr.isel(time=2).rio.clip(shdf, crs=ds.pr.rio.crs).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub.pr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model configuration parameters\n",
    "config = dict(\n",
    "    start_date=start, \n",
    "    end_date=stop,\n",
    "    area=basin_area,\n",
    "    elevation=basin_elevation,\n",
    "    latitude=basin_latitude,\n",
    "    longitude=basin_longitude,\n",
    "    run_name='test_' + dataset + '_' + hydromodel,\n",
    "    nc_spec= nc_transforms\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here is where the magic happens, and the RAVEN modeling framework parses the information that we give it\n",
    "# to run the hydrological model that we chose with the dataset that we chose.\n",
    "\n",
    "# Here we provide a set of hydrological model parameters by default, but these can be adjusted, modified or calibrated later.\n",
    "if hydromodel=='HMETS':\n",
    "    params = '9.5019, 0.2774, 6.3942, 0.6884, 1.2875, 5.4134, 2.3641, 0.0973, 0.0464, 0.1998, 0.0222, -1.0919,2.6851, 0.3740, 1.0000, 0.4739, 0.0114, 0.0243, 0.0069, 310.7211, 916.1947'\n",
    "    resp = wps.raven_hmets(ts=str(tsfile), params=params, rain_snow_fraction='RAINSNOW_DINGMAN', **config,)\n",
    "    \n",
    "elif hydromodel=='GR4JCN':\n",
    "    params = '0.529, -3.396, 407.29, 1.072, 16.9, 0.947'\n",
    "    resp = wps.raven_gr4j_cemaneige(ts=str(tsfile), params = params, **config)\n",
    "    \n",
    "elif hydromodel=='MOHYSE':\n",
    "    params = '1.00, 0.0468, 4.2952, 2.6580, 0.4038, 0.0621, 0.0273, 0.0453'\n",
    "    hrus = '0.9039, 5.6179775' # MOHYSE has a particular setup that requires parameters for HRUs.\n",
    "    resp = wps.raven_mohyse(ts=str(tsfile), params = params, hrus=hrus, rain_snow_fraction='RAINSNOW_DINGMAN', **config)  \n",
    "    \n",
    "elif hydromodel=='HBVEC':\n",
    "    params = '0.05984519, 4.072232, 2.001574, 0.03473693, 0.09985144, 0.5060520, 3.438486, 38.32455, 0.4606565, 0.06303738, 2.277781, 4.873686, 0.5718813, 0.04505643, 0.877607, 18.94145, 2.036937, 0.4452843, 0.6771759, 1.141608, 1.024278'\n",
    "    resp = wps.raven_hbv_ec(ts=str(tsfile), evaporation=\"PET_OUDIN\", ow_evaporation=\"PET_OUDIN\", params=params, **config)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The model has run! We can get the response.\n",
    "# With `asobj` set to False, only the reference to the output is returned in the response. \n",
    "# Setting `asobj` to True will retrieve the actual files and copy them locally. \n",
    "[hydrograph, storage, solution, diagnostics, rv] = resp.get(asobj=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we requested output objects, we can simply access the output objects. The dianostics is just a CSV file: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(diagnostics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `hydrograph` and `storage` outputs are netCDF files storing the time series. These files are opened by default using `xarray`, which provides convenient and powerful time series analysis and plotting tools. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hydrograph.q_sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas.plotting import register_matplotlib_converters\n",
    "register_matplotlib_converters()\n",
    "\n",
    "hydrograph.q_sim.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Max: \", hydrograph.q_sim.max())\n",
    "print(\"Mean: \", hydrograph.q_sim.mean())\n",
    "print(\"Monthly means: \", hydrograph.q_sim.groupby(hydrograph.time.dt.month).mean(dim='time'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## If we want, we can also download the simulation data and analyze it on our own computer, software and tools:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-extract the WPS Server response, but this time set the \"asobj\" to False to return the file path.\n",
    "[hydrograph, storage, solution, diagnostics, rv] = resp.get(asobj=False)\n",
    "print(hydrograph)\n",
    "print(storage)\n",
    "print(solution)\n",
    "print(diagnostics)\n",
    "print(rv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
