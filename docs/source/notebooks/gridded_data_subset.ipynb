{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Averaging climate variables over a watershed using a polygon\n",
    "\n",
    "\n",
    "This notebook is similar to the previous one, but shows how data averaging can be done locally instead of remotely, on a user-defined watershed. The watershed contour is provided by a shapefile, which we use to subset meteorological data and to extract watershed physiographic properties. The meteorological data is spatially averaged, then fed to the Raven hydrological model to simulate streamflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from zipfile import ZipFile\n",
    "import json\n",
    "import os\n",
    "import datetime as dt\n",
    "import tempfile\n",
    "from birdy import WPSClient\n",
    "import fiona\n",
    "import xarray as xr\n",
    "import rioxarray\n",
    "\n",
    "from ravenpy.utilities.testdata import get_file\n",
    "\n",
    "# Disable Dataset.__repr_html_ and DataArray._repr_html_, enabled by default in xarray 0.15.1\n",
    "xr.set_options(display_style='text')\n",
    "\n",
    "# Set environment variable WPS_URL to \"http://localhost:9099\" to run on the default local server\n",
    "url = os.environ.get(\"WPS_URL\", \"https://pavics.ouranos.ca/twitcher/ows/proxy/raven/wps\")\n",
    "wps = WPSClient(url)\n",
    "\n",
    "# Temporary directory to store meteorological data\n",
    "tmp = Path(tempfile.mkdtemp())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The file location is: /home/david/.raven_testing_data/master/watershed_vector/LSJ_LL.zip\n"
     ]
    }
   ],
   "source": [
    "# SETUP THE RUN PARAMETERS. The data will be extracted to cover the simulation period\n",
    "\n",
    "start = dt.datetime(2001, 1, 1)\n",
    "stop = dt.datetime(2002, 12, 31)\n",
    "UTCoffset_hours = -6 # for UTC delta\n",
    "\n",
    "# The shapefile of the catchment. All files (.shp, .shx, etc.) must be zipped into one file. \"vec\" is a string\n",
    "# or Posix Path pointing to the zipped watershed contour file location.\n",
    "vec = get_file(\"watershed_vector/LSJ_LL.zip\")\n",
    "print(\"The file location is: \" + str(vec))\n",
    "\n",
    "# Choose a dataset to use. We have 'NRCAN' and 'ERA5' for now.\n",
    "# NRCAN is only available in Canada, while ERA5 is global.\n",
    "dataset = 'ERA5'\n",
    "\n",
    "# Choose a hydrological model to use. We have 'HMETS', 'GR4JCN','MOHYSE' and 'HBVEC'.\n",
    "hydromodel = 'HMETS'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/david/.conda/envs/birdy/lib/python3.7/site-packages/ipykernel_launcher.py:12: FionaDeprecationWarning: Collection.__next__() is buggy and will be removed in Fiona 2.0. Switch to `next(iter(collection))`.\n",
      "  if sys.path[0] == '':\n"
     ]
    }
   ],
   "source": [
    "# We will first need to process the catchment boundaries from the zipped shapefile.\n",
    "ZipFile(vec,'r').extractall(tmp)\n",
    "shp = list(tmp.glob(\"*.shp\"))[0]\n",
    "vector = fiona.open(shp, \"r\")\n",
    "\n",
    "lon_min=vector.bounds[0]\n",
    "lon_max=vector.bounds[2]\n",
    "lat_min=vector.bounds[1]\n",
    "lat_max=vector.bounds[3]\n",
    "\n",
    "# Get access to the geometry using the fiona API\n",
    "shdf = [vector.next()[\"geometry\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Area:  44877.18805296849\n",
      "Elevation:  404.70781406591504\n",
      "Longitude:  -72.69128332186324\n",
      "Latitude:  49.501193631231935\n"
     ]
    }
   ],
   "source": [
    "# From the shapefile, call the PAVICS-Hydro service to extract properties such as centroid lat/long, elevation and area.\n",
    "resp = wps.shape_properties(shape=str(vec))\n",
    "[properties, ]=resp.get(asobj=True)\n",
    "prop = properties[0]\n",
    "basin_area = prop['area']/1000000.0\n",
    "basin_longitude = prop['centroid'][0]\n",
    "basin_latitude = prop['centroid'][1]\n",
    "\n",
    "# This uses the HydroSheds DEM\n",
    "resp = wps.terrain_analysis(shape=str(vec), select_all_touching=True, projected_crs=3978)\n",
    "properties, dem = resp.get(asobj=True)\n",
    "basin_elevation=properties[0]['elevation']\n",
    "\n",
    "print(\"Area: \", basin_area)\n",
    "print(\"Elevation: \", basin_elevation)\n",
    "print(\"Longitude: \", basin_longitude)\n",
    "print(\"Latitude: \", basin_latitude)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "if dataset=='NRCAN':\n",
    "    # Define the path to the netcdf file and write to disk (the basin averaged data)\n",
    "    tsfile= tmp / 'NRCAN_ts.nc'\n",
    "\n",
    "    if not tsfile.exists():\n",
    "        # Path to unified NetCDF ML dataset file on the THREDDS server (OPeNDAP link)\n",
    "        NRCAN_url='https://pavics.ouranos.ca/twitcher/ows/proxy/thredds/dodsC/datasets/gridded_obs/nrcan_v2.ncml'\n",
    "\n",
    "        #Open the dataset file and slice the desired lat/lon (+1Â°Buffer) and limit to the time simulation duration\n",
    "        ds=xr.open_dataset(NRCAN_url).sel(lat=slice(lat_max+1,lat_min-1), lon=slice(lon_min-1,lon_max+1), time=slice(start, stop))\n",
    "\n",
    "        # Rioxarray requires CRS definitions for variables\n",
    "        tas = ds.tas.rio.write_crs(4326)\n",
    "        pr = ds.pr.rio.write_crs(4326)\n",
    "        ds = xr.merge([tas, pr])\n",
    "\n",
    "        # Now apply the mask of the basin contour and average the values to get a single time series\n",
    "        sub = ds.rio.clip(shdf, crs=4326)\n",
    "        sub = sub.mean(dim={'lat','lon'}, keep_attrs=True)\n",
    "\n",
    "        # Define the path to the netcdf file and write to disk (the basin averaged data)\n",
    "        sub.to_netcdf(tsfile)\n",
    "\n",
    "    # Prepare the linear transform parameters for the hydrological model run.\n",
    "    nc_transforms = json.dumps({'tasmax': {'linear_transform': (1.0, -273.15)},'tasmin': {'linear_transform': (1.0, -273.15)},'pr': {'linear_transform': (86400.0, 0.0)}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "if dataset=='ERA5':\n",
    "    tsfile=tmp / 'ERA5_ts.nc'\n",
    "    day = dt.timedelta(days=1)\n",
    "    if not tsfile.exists():\n",
    "        ERA5_url='https://pavics.ouranos.ca/twitcher/ows/proxy/thredds/dodsC/datasets/reanalyses/era5.ncml'\n",
    "        ds=xr.open_dataset(ERA5_url).sel(latitude=slice(lat_max+1,lat_min-1), longitude=slice(lon_min+360-1,lon_max+360+1),time=slice(start - day, stop + day))\n",
    "\n",
    "        # Special treatment for ERA5 in North America: ECMWF stores ERA5 longitude in 0:360 format rather than -180:180. We need to reassign the longitudes here\n",
    "        ds = ds.assign_coords({'longitude':ds['longitude'].values[:]-360})\n",
    "\n",
    "        # Rioxarray requires CRS definitions for variables\n",
    "        tas = ds.tas.rio.write_crs(4326)\n",
    "        pr = ds.pr.rio.write_crs(4326)\n",
    "        ds = xr.merge([tas, pr])\n",
    "\n",
    "        sub = ds.rio.clip(shdf, crs=ds.tas.rio.crs)\n",
    "        sub = sub.mean(dim={'latitude','longitude'}, keep_attrs=True)\n",
    "\n",
    "        # Define the path to the netcdf file and write to disk (the basin averaged data)\n",
    "        sub.to_netcdf(tsfile)\n",
    "\n",
    "    #Perform the linear transform and time shift\n",
    "    nc_transforms=json.dumps({'tas': {'linear_transform': (1.0, -273.15), 'time_shift': UTCoffset_hours/24}, 'pr': {'linear_transform': (24000.0, 0.0), 'time_shift': UTCoffset_hours/24}})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.QuadMesh at 0x7f1ea83908d0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Map of precip snapshot\n",
    "ds.pr.isel(time=2).rio.clip(shdf, crs=ds.pr.rio.crs).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre>&lt;xarray.DataArray &#x27;pr&#x27; (time: 17545)&gt;\n",
       "array([1.9725623e-05, 2.7161006e-05, 3.7725804e-05, ..., 7.4663832e-05,\n",
       "       5.3332824e-05, 3.2710970e-05], dtype=float32)\n",
       "Coordinates:\n",
       "  * time         (time) datetime64[ns] 2000-12-31 ... 2003-01-01\n",
       "    spatial_ref  int64 0\n",
       "Attributes:\n",
       "    units:         m\n",
       "    long_name:     Total precipitation\n",
       "    grid_mapping:  spatial_ref</pre>"
      ],
      "text/plain": [
       "<xarray.DataArray 'pr' (time: 17545)>\n",
       "array([1.9725623e-05, 2.7161006e-05, 3.7725804e-05, ..., 7.4663832e-05,\n",
       "       5.3332824e-05, 3.2710970e-05], dtype=float32)\n",
       "Coordinates:\n",
       "  * time         (time) datetime64[ns] 2000-12-31 ... 2003-01-01\n",
       "    spatial_ref  int64 0\n",
       "Attributes:\n",
       "    units:         m\n",
       "    long_name:     Total precipitation\n",
       "    grid_mapping:  spatial_ref"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub.pr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model configuration parameters\n",
    "config = dict(\n",
    "    start_date=start,\n",
    "    end_date=stop,\n",
    "    area=basin_area,\n",
    "    elevation=basin_elevation,\n",
    "    latitude=basin_latitude,\n",
    "    longitude=basin_longitude,\n",
    "    run_name='test_' + dataset + '_' + hydromodel,\n",
    "    nc_spec= nc_transforms\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here is where the magic happens, and the RAVEN modeling framework parses the information that we give it\n",
    "# to run the hydrological model that we chose with the dataset that we chose.\n",
    "\n",
    "# Here we provide a set of hydrological model parameters by default, but these can be adjusted, modified or calibrated later.\n",
    "if hydromodel=='HMETS':\n",
    "    params = '9.5019, 0.2774, 6.3942, 0.6884, 1.2875, 5.4134, 2.3641, 0.0973, 0.0464, 0.1998, 0.0222, -1.0919,2.6851, 0.3740, 1.0000, 0.4739, 0.0114, 0.0243, 0.0069, 310.7211, 916.1947'\n",
    "    resp = wps.raven_hmets(ts=str(tsfile), params=params, rain_snow_fraction='RAINSNOW_DINGMAN', **config,)\n",
    "\n",
    "elif hydromodel=='GR4JCN':\n",
    "    params = '0.529, -3.396, 407.29, 1.072, 16.9, 0.947'\n",
    "    resp = wps.raven_gr4j_cemaneige(ts=str(tsfile), params = params, **config)\n",
    "\n",
    "elif hydromodel=='MOHYSE':\n",
    "    params = '1.00, 0.0468, 4.2952, 2.6580, 0.4038, 0.0621, 0.0273, 0.0453'\n",
    "    hrus = '0.9039, 5.6179775' # MOHYSE has a particular setup that requires parameters for HRUs.\n",
    "    resp = wps.raven_mohyse(ts=str(tsfile), params = params, hrus=hrus, rain_snow_fraction='RAINSNOW_DINGMAN', **config)\n",
    "\n",
    "elif hydromodel=='HBVEC':\n",
    "    params = '0.05984519, 4.072232, 2.001574, 0.03473693, 0.09985144, 0.5060520, 3.438486, 38.32455, 0.4606565, 0.06303738, 2.277781, 4.873686, 0.5718813, 0.04505643, 0.877607, 18.94145, 2.036937, 0.4452843, 0.6771759, 1.141608, 1.024278'\n",
    "    resp = wps.raven_hbv_ec(ts=str(tsfile), evaporation=\"PET_OUDIN\", ow_evaporation=\"PET_OUDIN\", params=params, **config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "ServiceException",
     "evalue": "<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<!-- PyWPS 4.2.9 -->\n<ows:ExceptionReport xmlns:ows=\"http://www.opengis.net/ows/1.1\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://www.opengis.net/ows/1.1 http://schemas.opengis.net/ows/1.1.0/owsExceptionReport.xsd\" version=\"1.0.0\">\n  <ows:Exception exceptionCode=\"MissingParameterValue\" locator=\"service\" >\n      <ows:ExceptionText>service</ows:ExceptionText>\n  </ows:Exception>\n</ows:ExceptionReport>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mServiceException\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-1be938d4d740>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# With `asobj` set to False, only the reference to the output is returned in the response.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Setting `asobj` to True will retrieve the actual files and copy them locally.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;34m[\u001b[0m\u001b[0mhydrograph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstorage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msolution\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdiagnostics\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrv\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0masobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.conda/envs/birdy/lib/python3.7/site-packages/birdy/client/outputs.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, asobj)\u001b[0m\n\u001b[1;32m     29\u001b[0m             \u001b[0;31m# TODO: add reason for failure\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mProcessFailed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Sorry, process failed.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0masobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvert_objects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/birdy/lib/python3.7/site-packages/birdy/client/outputs.py\u001b[0m in \u001b[0;36m_make_output\u001b[0;34m(self, convert_objects)\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0mOutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__repr__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpretty_repr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m         return Output(\n\u001b[0;32m---> 40\u001b[0;31m             \u001b[0;34m*\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvert_objects\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocessOutputs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m         )\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/birdy/lib/python3.7/site-packages/birdy/client/outputs.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0mOutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__repr__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpretty_repr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m         return Output(\n\u001b[0;32m---> 40\u001b[0;31m             \u001b[0;34m*\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvert_objects\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocessOutputs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m         )\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/birdy/lib/python3.7/site-packages/birdy/client/outputs.py\u001b[0m in \u001b[0;36m_process_output\u001b[0;34m(self, output, convert_objects)\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mconvert_objects\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_converters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverify\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreference\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/birdy/lib/python3.7/site-packages/birdy/client/converters.py\u001b[0m in \u001b[0;36mconvert\u001b[0;34m(output, path, converters, verify)\u001b[0m\n\u001b[1;32m    327\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    328\u001b[0m             \u001b[0mconverter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverify\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverify\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 329\u001b[0;31m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconverter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    330\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mconverter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnested\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Then the output is a list of files.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    331\u001b[0m                 \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/birdy/lib/python3.7/site-packages/birdy/client/converters.py\u001b[0m in \u001b[0;36mconvert\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     83\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m         \u001b[0;34m\"\"\"Return text content.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 85\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"utf8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/birdy/lib/python3.7/site-packages/birdy/client/converters.py\u001b[0m in \u001b[0;36mfile\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0;34m\"\"\"Return output Path object. Download from server if \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_file\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwriteToDisk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverify\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverify\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilePath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/birdy/lib/python3.7/site-packages/OWSLib-0.19.2-py3.7.egg/owslib/wps.py\u001b[0m in \u001b[0;36mwriteToDisk\u001b[0;34m(self, path, username, password, headers, verify, cert)\u001b[0m\n\u001b[1;32m   1446\u001b[0m         \"\"\"\n\u001b[1;32m   1447\u001b[0m         \u001b[0;31m# Check if ExecuteResponse contains reference to server-side output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1448\u001b[0;31m         \u001b[0mcontent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieveData\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0musername\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpassword\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverify\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverify\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcert\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1449\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1450\u001b[0m         \u001b[0;31m# ExecuteResponse contain embedded output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/birdy/lib/python3.7/site-packages/OWSLib-0.19.2-py3.7.egg/owslib/wps.py\u001b[0m in \u001b[0;36mretrieveData\u001b[0;34m(self, username, password, headers, verify, cert)\u001b[0m\n\u001b[1;32m   1428\u001b[0m             u = openURL(\n\u001b[1;32m   1429\u001b[0m                 \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Get'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0musername\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0musername\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpassword\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpassword\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1430\u001b[0;31m                 headers=headers, verify=verify, cert=cert)\n\u001b[0m\u001b[1;32m   1431\u001b[0m             \u001b[0;31m# extract output filepath from base URL\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1432\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfileName\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/birdy/lib/python3.7/site-packages/OWSLib-0.19.2-py3.7.egg/owslib/util.py\u001b[0m in \u001b[0;36mopenURL\u001b[0;34m(url_base, data, method, cookies, username, password, timeout, headers, verify, cert, auth)\u001b[0m\n\u001b[1;32m    205\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus_code\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m400\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m401\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 207\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mServiceException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    208\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    209\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus_code\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m404\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m500\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m502\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m503\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m504\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# add more if needed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mServiceException\u001b[0m: <?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<!-- PyWPS 4.2.9 -->\n<ows:ExceptionReport xmlns:ows=\"http://www.opengis.net/ows/1.1\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://www.opengis.net/ows/1.1 http://schemas.opengis.net/ows/1.1.0/owsExceptionReport.xsd\" version=\"1.0.0\">\n  <ows:Exception exceptionCode=\"MissingParameterValue\" locator=\"service\" >\n      <ows:ExceptionText>service</ows:ExceptionText>\n  </ows:Exception>\n</ows:ExceptionReport>"
     ]
    }
   ],
   "source": [
    "# The model has run! We can get the response.\n",
    "# With `asobj` set to False, only the reference to the output is returned in the response.\n",
    "# Setting `asobj` to True will retrieve the actual files and copy them locally.\n",
    "[hydrograph, storage, solution, diagnostics, rv] = resp.get(asobj=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we requested output objects, we can simply access the output objects. The dianostics is just a CSV file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(diagnostics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `hydrograph` and `storage` outputs are netCDF files storing the time series. These files are opened by default using `xarray`, which provides convenient and powerful time series analysis and plotting tools."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hydrograph.q_sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas.plotting import register_matplotlib_converters\n",
    "register_matplotlib_converters()\n",
    "\n",
    "hydrograph.q_sim.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Max: \", hydrograph.q_sim.max())\n",
    "print(\"Mean: \", hydrograph.q_sim.mean())\n",
    "print(\"Monthly means: \", hydrograph.q_sim.groupby(hydrograph.time.dt.month).mean(dim='time'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we want, we can also download the simulation data and analyze it on our own computer, software and tools:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-extract the WPS Server response, but this time set the \"asobj\" to False to return the file path.\n",
    "[hydrograph, storage, solution, diagnostics, rv] = resp.get(asobj=False)\n",
    "print(hydrograph)\n",
    "print(storage)\n",
    "print(solution)\n",
    "print(diagnostics)\n",
    "print(rv)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
