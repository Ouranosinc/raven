{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HPC demo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "This notebook shows how to use the distributed [raven/ostrich module](https://github.com/Ouranosinc/raven/wiki/Technical-Notes) on Compute Canada infrastructure. It runs a complete example of transferring local input data files required by raven/ostrich, running the tool remotely and retrieving the results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Design & strategy\n",
    "Four issues arose during the module design stage:\n",
    "* Authentication: how to access Compute Canada (CC) infrastructure\n",
    "* Job submission: how to interact with CC's job scheduler\n",
    "* Data transfer: how to copy the local data remotely and retrieve the generated output files\n",
    "* Executable setup: how to configure a CC endpoint to invoke either _raven_/_ostrich_ binaries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Authentication\n",
    "The initial objective was to allow users to use their own credentials when running jobs on a CC cluster. This proved to be complicated because it would force users to upload their private keys to the server hosting the module (potential key compromission in the event of a security breach). A simpler approach has been adopted: create a _common_ user on CC side (called _crim01_) and execute jobs on its behalf."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Job submission\n",
    "Compute Canada does not provide rest APIs to allow job submissions from remote applications. Such tools exist but their deployment is rather a long-term plan on CC's roadmap. The unique solution is to take advantage of ssh's ability to execute commands on a remote machine, where commands in this context are the slurm utilities for job management (_sbatch_ for submission, _sacct_ for status enquiry and _scancel_ for job suppression). For our concern, jobs have four states: \"PENDING\" (sitting in the job queue), \"RUNNING\" (execution), \"TIMEOUT\" (job took too long to execute) and \"CANCEL\" (job was killed by the user)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data transfer\n",
    "Again, the lack of public API imposes the use of \"simple\" tools such as _tar_ and _scp_ for data transfer. The series of steps include tarring the local input data (sitting in a directory whose path is provided to the module by the user), copying the tar file to crim01's working directory, untarring, running the job, tarring the results, copying the results tar file back to the caller (the module) and untarring it inside the directory provided by the user."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Executable setup\n",
    "The most elegant way to invoke either _raven_ or _ostrich_ on CC side is to launch a container that is configured to execute them. Predefined paths inside the container are mapped to subfolders in CRIM01's working directory and raven/ostrich are configured to make use of those predefined paths, for reading the parameter files and writing the output results. When thinking of containers, docker comes to mind but this technology is reportedly not appropriate for high-performance computing (https://dev.to/grokcode/singularity--a-docker-for-hpc-environments-i6p), so this is why Singularity has been chosen as container platform. Two Singularity images (one for _raven_, one for _ostrich_) are hosted in a public registry that has been set up at CRIM (132.217.141.54); when slurm schedules the job for execution (state RUNNING), the Singularity command-line tool pulls the appropriate image from the registry and executes it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Requirements\n",
    "The module is easy to install and use, its single dependency being ParallelSSH (https://pypi.org/project/parallel-ssh/)\n",
    "\n",
    "`$ pip install parallel_ssh`\n",
    "\n",
    "In addition, the module expects the existence of a writable /tmp directory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Usage example\n",
    "The follwing shows how to use the module: data is sent to a ComputeCanada cluster named cedar, a job involving either _raven_ or _ostrich_ is submitted and after execution (which may take a few minutes) the results are brought back locally. For this notebook, the default subdirectory 'test_data' contains examples for the mohyse-salmon dataset only.\n",
    "\n",
    "_Note: be sure to execute cells only once, as job submission, an atomic operation by design, has been broken into many steps for demo purposes._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directories\n",
    "src_data_dir = \"./\"\n",
    "out_dir = \"./\"\n",
    "template_dir = \"./template/\"\n",
    "executable = 'raven'\n",
    "def my_function(x):\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Executable selection\n",
    "import os\n",
    "import datetime\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import interactive\n",
    "from IPython.display import display\n",
    "x=widgets.Dropdown(\n",
    "    options=['raven', 'ostrich'],\n",
    "    value='raven',\n",
    "    description='Executable',\n",
    "    disabled=False,\n",
    ")\n",
    "wd=widgets.Dropdown(\n",
    "    options=['mohyse-salmon'],  #,'hmets-salmon', 'gr4j-salmon','hbv-salmon'],\n",
    "    value='mohyse-salmon',\n",
    "    description='Dataset',\n",
    "    disabled=False,\n",
    ")\n",
    "\n",
    "w=interactive(my_function, x=x)\n",
    "\n",
    "display(w)\n",
    "d=interactive(my_function, x=wd)\n",
    "display(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "executable=w.children[0].value\n",
    "dataset=executable + \"-\"+d.children[0].value\n",
    "print(\"{}: {}\".format(executable,dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select data paths\n",
    "\n",
    "Two paths must be provided to the module:\n",
    "* The source path containing the input data files\n",
    "* The output path that will hold the files generated by the executable on the cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wsrcpath=widgets.Text(\n",
    "    value=os.path.join(os.getcwd(),\"test_data\"),\n",
    "    placeholder='Source data path',\n",
    "    description='Source data path:',\n",
    "    disabled=False)\n",
    "i_wsrcpath=interactive(my_function, x=wsrcpath)\n",
    "display(i_wsrcpath)\n",
    "woutpath=widgets.Text(\n",
    "    value=os.path.join(os.getcwd(),'output'),\n",
    "    placeholder='Output data path',\n",
    "    description='Output data path:',\n",
    "    disabled=False)\n",
    "i_woutpath=interactive(my_function, x=woutpath)\n",
    "display(i_woutpath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check connections\n",
    "The module provides a function that performs two basic network connection checks:\n",
    "* Is the access to the cluster allowed (i.e. can the module connect to its account)?\n",
    "* Is the Singularity registry responding to a ping request?\n",
    "\n",
    "Note: make sure that the path to the private key for ssh (supplied to the constructor of RavenHPCProcess) is good and that its permissions are [appropriate](http://www.sciencebits.com/Setting-SSH-Keys)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "src_data_dir = i_wsrcpath.children[0].value\n",
    "out_dir = i_woutpath.children[0].value\n",
    "\n",
    "import raven_process\n",
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s %(message)s', level=logging.DEBUG, filename=\"hpclog.txt\", filemode='w') \n",
    "raven_proc = raven_process.RavenHPCProcess(executable, {\"src_data_path\": src_data_dir,\n",
    "                                                       \"ssh_key_filename\":\"~/.ssh/pavics-hydro-crim01\"})\n",
    "status, msg = raven_proc.check_connection()\n",
    "if status:\n",
    "   print(\"Network connections are ok\")\n",
    "else:\n",
    "   print(\"Network error: \"+msg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estimate job duration\n",
    "\n",
    "The job submission process requires the user to provide an *upper bound* estimate of the time needed to carry out the computations. \n",
    "* If the estimate is too low, the job may be killed before completion (when the computation time reaches the estimate)\n",
    "* If the estimate is too high, the job may be scheduled with a lower priority.\n",
    "Note that 20min will be added to the estimate to account for the download of the raven or ostrich singularity image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wduration=widgets.IntText(\n",
    "    value=10,\n",
    "    description='Job duration estimate (min):',\n",
    "    disabled=False\n",
    ")\n",
    "i_wdur=interactive(my_function, x=wduration)\n",
    "display(i_wdur)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Job summary before submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_duration = str(datetime.timedelta(minutes=int(i_wdur.children[0].value) + 20))\n",
    "print(\"Executable: {}\".format(executable))\n",
    "print(\"Dataset: {}\".format(dataset))\n",
    "print(\"Source data path: {}\".format(src_data_dir))\n",
    "print(\"Output path: {}\".format(out_dir))\n",
    "print(\"Time estimate: {}\".format(job_duration))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Job submission\n",
    "The job is ready to be submitted to slurm. Actual execution start time may be anywhere between a few seconds and many hours, depending on cluster load."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# jobinfo = process_cmd(executable, client,hostname,\"Submit\")\n",
    "print(\"Submitting job...\")\n",
    "try:\n",
    "    raven_proc.submit(dataset, job_duration)    \n",
    "    print(\"Job ID: {}\".format(raven_proc.live_job_id))\n",
    "    \n",
    "except Exception as e:\n",
    "    print(\"Job submission failed: {}\".format(e))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Polling for results\n",
    "Once the job is queued, a monitoring function can be called to query its status (PENDING, RUNNING, etc.) When the job is in the RUNNING state, _raven_ or _ostrich_ is being executed and in both cases a progress figure (between 0% and 100%) is sent to the caller (here, the notebook cell). This figure may not always be available due to the fact that it is extracted from a text file being overwritten on a continuous basis.\n",
    "\n",
    "The caller will typically invoke this monitoring function inside a while loop, leaving the loop upon termination of the execution (job completed or error); a reasonable call frequency could be one call per minute, as shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "wprog = widgets.IntProgress(\n",
    "    value=0,\n",
    "    min=0,\n",
    "    max=100,\n",
    "    step=1,\n",
    "    description='Progress',\n",
    "    bar_style='', # 'success', 'info', 'warning', 'danger' or ''\n",
    "    orientation='horizontal'\n",
    ")\n",
    "display(wprog)\n",
    "wtext = widgets.HTML(\n",
    "    value=\"\",style={'description_width': 'initial'},\n",
    "    description='Received status',\n",
    "    placeholder='Progress'\n",
    ")\n",
    "display(wtext)\n",
    "\n",
    "i = 0\n",
    "import time\n",
    "job_finished = False\n",
    "abnormal_ending = False\n",
    "while not job_finished:\n",
    "\n",
    "        time.sleep(60)\n",
    "        try:\n",
    "\n",
    "            out, p = raven_proc.monitor()\n",
    "            #print(out)\n",
    "            wtext.value += out+\"<p>\"\n",
    "            if out == \"RUNNING\":\n",
    "                #print(\"{}%\".format(p))\n",
    "                i+=1\n",
    "                wprog.value = int(p)\n",
    "            if out == \"COMPLETED\":\n",
    "                job_finished = True\n",
    "            if out == \"TIMEOUT\" or out == \"CANCELLED\":\n",
    "                print(\"Uhoh: job \"+out)\n",
    "                abnormal_ending = True\n",
    "                job_finished = True\n",
    "            if out is None:\n",
    "                print(\"Temp error\")\n",
    "            # Test job cancellation during job exec    \n",
    "            # if i==2:\n",
    "            #    raven_proc.cancel()\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(\"Exception @monitor\")\n",
    "            print(e)\n",
    "            #job_finished = True\n",
    "\n",
    "    # Check if job ended  normally\n",
    "if abnormal_ending:\n",
    "     print(\"Job ended abnormally\")\n",
    "     raven_proc.retrieve(out_dir)  # to get slurm log file\n",
    "\n",
    "else:\n",
    "     wprog.value = 100\n",
    "     print(\"Retrieving results...\")\n",
    "     raven_proc.retrieve(out_dir)\n",
    "     print(\"Results are ready: in {}\".format(out_dir))\n",
    "\n",
    "raven_proc.cleanup()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At that point, if everything went well (no errors in input data, no job cancellation, etc.), the execution results will be found in the output directory, along with the log file generated by the job scheduler (slurm)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Additional notes\n",
    "* Parallel invocations are supported: each module instance has its own workspace on ComputeCanada side, so many server sessions can manage jobs simultaneously.\n",
    "* A nice advantage of the proposed implementation is the use of deployment: no requirements as far as ComputeCanada is concerned (no package to install or service to start), except an ssh connection and some user space.\n",
    "* Limitation: module operation is bound by the rules in effect at ComputeCanada governing job management. For example, a directive issued in April 2019 announced a new rule that prevents user from submitting jobs from their /home directory; fixes to the module have been made but this kind of issue can still arise in the future."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
